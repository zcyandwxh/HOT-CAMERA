server.port=9090
server.tomcat.max-http-post-size=-1
spring.jackson.property-naming-strategy=LOWER_CAMEL_CASE
#server.address=192.168.56.11
#================springboot自动配置kafka===============#
#============== config ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=hadoop101:9092,hadoop102:9092,hadoop103:9092

#=============== provider  =======================

spring.kafka.producer.retries=2
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.file.propertiesbuffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group idkafka.producer.servers
spring.kafka.consumer.group-id=pic-consumer-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

##原始数据kafka读取
#kafka.consumer.servers=hadoop101:9092,hadoop102:9092,hadoop103:9092
#kafka.consumer.enable.auto.commit=true
#kafka.consumer.session.timeout=20000
#kafka.consumer.auto.commit.interval=100
#kafka.consumer.auto.offset.reset=latest
#kafka.consumer.topic=result
#kafka.consumer.group.id=test
#kafka.consumer.concurrency=10
#
##协议转换后存储kafka
#kafka.producer.servers=hadoop101:9092,hadoop102:9092,hadoop103:9092
#kafka.producer.topic=result
#kafka.producer.retries=0
#kafka.producer.batch.size=4096
#kafka.producer.linger=1
#kafka.producer.buffer.memory=40960

##Netty相关配置
tcp.port=9091
# bossGroup的线程数
boss.thread.count=2
# worker的线程数
worker.thread.count=2
#是否使用长连接
so.keepalive=true
so.backlog=100
